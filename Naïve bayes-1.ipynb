{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4b4540-477d-4792-bf7e-4dc52f8fc700",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce64eed-ef9e-4223-a552-592cf404e665",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental concept in probability theory and statistics. It describes the probability of an event based on prior knowledge of conditions that might be related to the event. In essence, it provides a way to update our beliefs about an event in light of new evidence.\n",
    "\n",
    "Mathematical Representation\n",
    "\n",
    "Bayes' theorem is often expressed as:\n",
    "\n",
    "P(A|B) = [P(B|A) * P(A)] / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the conditional probability of event A occurring given that event B has already occurred. This is also known as the posterior probability.\n",
    "\n",
    "P(B|A) is the conditional probability of event B occurring given that event A has already occurred. This is known as the likelihood.\n",
    "\n",
    "P(A) is the prior probability of event A occurring. This represents our belief about the event before considering any new evidence.\n",
    "\n",
    "P(B) is the prior probability of event B occurring. This can be calculated using the law of total probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31400080-ee74-4d6e-ac8a-e10e95bb7047",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1f886-4ef7-4f4e-a38c-2c116e300b79",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the probability of event A happening given that event B has already happened. (Posterior probability)\n",
    "\n",
    "P(B|A) is the probability of event B happening given that event A has already happened. (Likelihood)\n",
    "\n",
    "P(A) is the probability of event A happening before considering event B. (Prior probability of A)\n",
    "\n",
    "P(B) is the probability of event B happening. (Evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b113c2-164e-43a9-aa0e-7c85e0bc57c3",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e52669-12cc-4e0a-9f31-b9645e889e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e7b1d-6812-4cb0-a4a1-d12c33a110ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "218be86d-5ed5-491b-bc92-4bf6d434c309",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f6467-1243-4660-86a4-42eb793f122d",
   "metadata": {},
   "source": [
    "Ans - Bayes' theorem is like a bridge between two related but different concepts in probability:\n",
    "\n",
    "1] Conditional Probability: This tells you the chance of something happening given that something else has already happened.  Think of it as narrowing down the possibilities based on some new information.\n",
    "\n",
    "2] Bayes' Theorem: This takes conditional probability a step further. It's a way to update your belief about the chance of something happening when you get new information.  It's like revising your initial guess (the \"prior\" probability) based on fresh evidence (the \"likelihood\").\n",
    "\n",
    "In simple words:\n",
    "\n",
    "Imagine you have a bag of marbles, some red and some blue.  You want to know the probability of picking a red marble (that's your prior probability).  You reach in without looking and pull out a marble, but you don't look at it yet.\n",
    "\n",
    "Now, someone tells you, \"The marble you picked is shiny.\"  This new information changes things. If you know shiny marbles are more likely to be blue, you'd revise your initial guess about the color of your marble. That's Bayes' theorem in action â€“ it helps you adjust your thinking based on what you learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0cc0d-f22c-406a-a18c-99629e094618",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc5554-713e-4f65-9767-6b8d5887c44e",
   "metadata": {},
   "source": [
    "1] Gaussian Naive Bayes:\n",
    "\n",
    "a. Data Type: Continuous numerical features\n",
    "\n",
    "b. Assumption: Features follow a normal (Gaussian) distribution.\n",
    "\n",
    "c. Example: Predicting house prices based on features like square footage, number of bedrooms, etc.\n",
    "\n",
    "2] Multinomial Naive Bayes:\n",
    "\n",
    "a. Data Type: Discrete counts (e.g., word frequencies in text)\n",
    "\n",
    "b. Assumption: Each feature represents the frequency of occurrence of an event.\n",
    "\n",
    "c. Example: Text classification tasks like spam detection, sentiment analysis, or topic categorization.\n",
    "\n",
    "3] Bernoulli Naive Bayes:\n",
    "a. Data Type: Binary features (0 or 1)\n",
    "\n",
    "b. Assumption: Each feature represents the presence or absence of an attribute.\n",
    "\n",
    "c. Example: Classifying documents based on the presence or absence of certain words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329b2c7-01e3-421b-9037-32320c87704b",
   "metadata": {},
   "source": [
    "Q6 Ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db912291-ff2c-43d9-9f8f-fc920764c50e",
   "metadata": {},
   "source": [
    "To predict the class of a new instance using Naive Bayes, we need to calculate the conditional probability of each class given the feature values.\n",
    "\n",
    "Given the table of frequencies, we can calculate the conditional probabilities for each class:\n",
    "\n",
    "P(A | X1 = 3, X2 = 4) = P(X1 = 3 | A) * P(X2 = 4 | A) * P(A) P(B | X1 = 3, X2 = 4) = P(X1 = 3 | B) * P(X2 = 4 | B) * P(B)\n",
    "\n",
    "Assuming equal prior probabilities for each class (P(A) = P(B) = 0.5), we can calculate the conditional probabilities as follows:\n",
    "\n",
    "P(X1 = 3 | A) = 4 / (3 + 4 + 3) = 0.4 P(X2 = 4 | A) = 3 / (4 + 3 + 3) = 0.3 P(X1 = 3 | B) = 1 / (2 + 2 + 1) = 0.2 P(X2 = 4 | B) = 3 / (2 + 2 + 3) = 0.3\n",
    "\n",
    "Substituting these values into the conditional probability formula:\n",
    "\n",
    "P(A | X1 = 3, X2 = 4) = 0.4 * 0.3 * 0.5 = 0.06 P(B | X1 = 3, X2 = 4) = 0.2 * 0.3 * 0.5 = 0.03\n",
    "\n",
    "Since P(A | X1 = 3, X2 = 4) > P(B | X1 = 3, X2 = 4), Naive Bayes would predict the new instance to belong to class A.\n",
    "\n",
    "Therefore, Naive Bayes would predict that the new instance with X1 = 3 and X2 = 4 belongs to class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8c1fc-986e-42ce-8d42-32891e17a654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
